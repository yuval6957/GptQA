{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# crowler\n",
    "\n",
    "> Wed Domain Crowler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp crowler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import requests\n",
    "import re\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import deque\n",
    "from html.parser import HTMLParser\n",
    "from urllib.parse import urlparse, urljoin, quote\n",
    "import os\n",
    "from typing import List, Optional\n",
    "from urllib.error import URLError, HTTPError\n",
    "from collections import deque\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Regex pattern to match a URL\n",
    "HTTP_URL_PATTERN = r'^http[s]*://.+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class HyperlinkParser(HTMLParser):\n",
    "    \"\"\" \n",
    "    A parser to extract hyperlinks from an HTML document.\n",
    "    Inherits from HTMLParser.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" Initialize the parser with an empty list of hyperlinks. \"\"\"\n",
    "        super().__init__()\n",
    "        self.hyperlinks = []\n",
    "\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        \"\"\" \n",
    "        Override the HTMLParser's handle_starttag method.\n",
    "        If the tag is an anchor tag and it has an href attribute, \n",
    "        add the href attribute to the list of hyperlinks.\n",
    "        \"\"\"\n",
    "        attrs = dict(attrs)\n",
    "        if tag == \"a\" and \"href\" in attrs:\n",
    "            self.hyperlinks.append(attrs[\"href\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_hyperlinks(url: str) -> List[str]:\n",
    "    \"\"\" \n",
    "    Function to get the hyperlinks from a URL. \n",
    "\n",
    "    Args:\n",
    "    url (str): The URL from which to extract hyperlinks.\n",
    "\n",
    "    Returns:\n",
    "    list[str]: A list of hyperlinks, or an empty list if the URL couldn't be opened or its content is not HTML.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Open the URL and read the HTML\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            # If the response is not HTML, return an empty list\n",
    "            if not response.info().get('Content-Type', '').startswith(\"text/html\"):\n",
    "                print(f\"Content at {url} is not HTML.\")\n",
    "                return []\n",
    "\n",
    "            # Decode the HTML\n",
    "            html = response.read().decode('utf-8')\n",
    "\n",
    "    except HTTPError as e:\n",
    "        print(f\"HTTP Error: {e.code} for url: {url}\")\n",
    "        return []\n",
    "    except URLError as e:\n",
    "        print(f\"URL Error: {e.reason} for url: {url}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "    # Create the HTML Parser and then Parse the HTML to get hyperlinks\n",
    "    parser = HyperlinkParser()\n",
    "    parser.feed(html)\n",
    "\n",
    "    return parser.hyperlinks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_domain_hyperlinks(local_domain: str, url: str) -> List[str]:\n",
    "    \"\"\" \n",
    "    Function to get the hyperlinks from a URL that are within the same domain.\n",
    "\n",
    "    Args:\n",
    "    local_domain (str): The local domain to match.\n",
    "    url (str): The URL from which to extract hyperlinks.\n",
    "\n",
    "    Returns:\n",
    "    list[str]: A list of hyperlinks within the same domain, or an empty list if the URL couldn't be opened or its content is not HTML.\n",
    "    \"\"\"\n",
    "    \n",
    "    clean_links = set()\n",
    "\n",
    "    for link in get_hyperlinks(url):\n",
    "        # Ignore anchors and mailto links\n",
    "        if link.startswith(\"#\") or link.startswith(\"mailto:\"):\n",
    "            continue\n",
    "\n",
    "        # Create absolute URL if the link is relative\n",
    "        abs_link = urljoin(url, link)\n",
    "\n",
    "        # Parse the URL and check if the domain is the same\n",
    "        url_obj = urlparse(abs_link)\n",
    "        if url_obj.netloc == local_domain:\n",
    "            clean_links.add(abs_link.rstrip('/'))\n",
    "\n",
    "    # Return the list of hyperlinks that are within the same domain\n",
    "    return list(clean_links)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def crawl(url: str, path: Optional[str] = \".\") -> None:\n",
    "    \"\"\" \n",
    "    Function to crawl a website starting from a given URL and save text content of each page to a file.\n",
    "\n",
    "    Args:\n",
    "    url (str): The URL to start crawling from.\n",
    "    path (str, optional): The path where to create a directory to store the text files. Defaults to the current directory.\n",
    "    \"\"\"\n",
    "\n",
    "    # Parse the URL and get the domain\n",
    "    local_domain = urlparse(url).netloc\n",
    "\n",
    "    # Create a queue to store the URLs to crawl\n",
    "    queue = deque([url])\n",
    "\n",
    "    # Create a set to store the URLs that have already been seen (no duplicates)\n",
    "    seen = set([url])\n",
    "\n",
    "    # Create a directory to store the text files\n",
    "    text_path = os.path.join(path, \"text\", local_domain)\n",
    "    os.makedirs(text_path, exist_ok=True)\n",
    "\n",
    "    # While the queue is not empty, continue crawling\n",
    "    while queue:\n",
    "        # Get the next URL from the queue\n",
    "        url = queue.pop()\n",
    "        print(f\"Crawling: {url}\")  # for debugging and to see the progress\n",
    "\n",
    "        try:\n",
    "            # Get the hyperlinks from the URL and add them to the queue\n",
    "            for link in get_domain_hyperlinks(local_domain, url):\n",
    "                if link not in seen:\n",
    "                    queue.append(link)\n",
    "                    seen.add(link)\n",
    "\n",
    "            # Read the content to retrieve text\n",
    "            get_request = requests.get(url)\n",
    "            get_request.raise_for_status()  # will raise HTTPError for bad status codes\n",
    "\n",
    "            # Get the text from the URL using BeautifulSoup\n",
    "            soup = BeautifulSoup(get_request.text, \"html.parser\")\n",
    "\n",
    "            # Get the text but remove the tags\n",
    "            text = soup.get_text()\n",
    "\n",
    "            # If the crawler gets to a page that requires JavaScript, it will stop the crawl\n",
    "            if \"You need to enable JavaScript to run this app.\" in text:\n",
    "                print(f\"Unable to parse page {url} due to JavaScript being required\")\n",
    "                continue\n",
    "\n",
    "            # Save text from the url to a <url>.txt file\n",
    "            filename = os.path.join(text_path, quote(url[8:], safe=\"\") + \".txt\")\n",
    "            with open(filename, \"w\", encoding=\"UTF-8\") as f:\n",
    "                f.write(text)\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request error for url: {url}. Error details: {str(e)}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error for url: {url}. Error details: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling: https://openai.com/\n",
      "Crawling: https://openai.com/pricing\n",
      "Crawling: https://openai.com/pricing#language-models\n",
      "Crawling: https://openai.com/contact-sales\n",
      "Crawling: https://openai.com/contact-sales#content\n",
      "Crawling: https://openai.com/customer-stories/stripe\n",
      "Crawling: https://openai.com/customer-stories?topics=language\n",
      "Crawling: https://openai.com/customer-stories/yabble\n",
      "Crawling: https://openai.com/customer-stories/yabble#content\n",
      "Crawling: https://openai.com/customer-stories#content\n",
      "Crawling: https://openai.com/customer-stories/government-of-iceland\n",
      "Crawling: https://openai.com/customer-stories/government-of-iceland#content\n",
      "Crawling: https://openai.com/customer-stories/inworld-ai\n",
      "Crawling: https://openai.com/customer-stories/inworld-ai#content\n",
      "Crawling: https://openai.com/customer-stories/be-my-eyes\n",
      "Crawling: https://openai.com/customer-stories/be-my-eyes#content\n",
      "Crawling: https://openai.com/customer-stories/duolingo\n",
      "Crawling: https://openai.com/customer-stories/duolingo#content\n",
      "Crawling: https://openai.com/customer-stories/waymark\n",
      "Crawling: https://openai.com/customer-stories/waymark#content\n",
      "Crawling: https://openai.com/customer-stories/khan-academy\n",
      "Crawling: https://openai.com/customer-stories/khan-academy#content\n",
      "Crawling: https://openai.com/customer-stories/stripe#content\n",
      "Crawling: https://openai.com/customer-stories/morgan-stanley\n",
      "Crawling: https://openai.com/customer-stories/morgan-stanley#content\n",
      "Crawling: https://openai.com/pricing#content\n",
      "Crawling: https://openai.com/safety-standards\n",
      "Crawling: https://openai.com/safety-standards#content\n",
      "Crawling: https://openai.com/research/dall-e-2-pre-training-mitigations\n",
      "Crawling: https://openai.com/research?contentTypes=conclusion\n",
      "Crawling: https://openai.com/research?topics=generative-models\n",
      "Crawling: https://openai.com/research/formal-math\n",
      "Crawling: https://openai.com/research/formal-math#content\n",
      "Crawling: https://openai.com/research?contentTypes=publication\n",
      "Crawling: https://openai.com/research?authors=jesse-michael-han\n",
      "Crawling: https://openai.com/research?authors=stanislas-polu\n",
      "Crawling: https://openai.com/research?authors=ilya-sutskever\n",
      "Crawling: https://openai.com/research/economic-impacts\n",
      "Crawling: https://openai.com/research/economic-impacts#content\n",
      "Crawling: https://openai.com/research?models=openai-codex\n",
      "Crawling: https://openai.com/blog/economic-impacts\n",
      "Crawling: https://openai.com/blog/economic-impacts#SamManning\n",
      "Crawling: https://openai.com/blog?topics=safety-alignment\n",
      "Crawling: https://openai.com/blog/discovering-the-minutiae-of-backend-systems\n",
      "Crawling: https://openai.com/blog/discovering-the-minutiae-of-backend-systems#content\n",
      "Crawling: https://openai.com/blog?topics=culture-and-careers\n",
      "Crawling: https://openai.com/blog/discovering-the-minutiae-of-backend-systems#OpenAI\n",
      "Crawling: https://openai.com/blog?authors=openai\n",
      "Crawling: https://openai.com/blog/openai-and-microsoft-extend-partnership\n",
      "Crawling: https://openai.com/blog/language-model-safety-and-misuse\n",
      "Crawling: https://openai.com/blog/language-model-safety-and-misuse/#misuse\n",
      "Crawling: https://openai.com/research?authors=katie-mayer\n",
      "Crawling: https://openai.com/blog/cooperation-on-safety\n",
      "Crawling: https://openai.com/research?authors=amanda-askell\n",
      "Crawling: https://openai.com/research?authors=jack-clark\n",
      "Crawling: https://openai.com/research/cooperation-on-safety#content\n",
      "Crawling: https://openai.com/blog/webgpt\n",
      "Crawling: https://openai.com/blog/webgpt/#samples\n",
      "Crawling: https://openai.com/blog/summarizing-books\n",
      "Crawling: https://openai.com/research?authors=ryan-lowe\n",
      "Crawling: https://openai.com/jobs\n",
      "Crawling: https://openai.com/careers/events-manager-communications\n",
      "Crawling: https://openai.com/careers/events-manager-communications#content\n",
      "Crawling: https://openai.com/careers/engineering-manager-chatgpt-infrastructure\n",
      "Crawling: https://openai.com/careers/engineering-manager-chatgpt-infrastructure#content\n",
      "Crawling: https://openai.com/careers/search\n",
      "Crawling: https://openai.com/careers/research-scientist-machine-learning\n",
      "Crawling: https://openai.com/careers/research-scientist-machine-learning#content\n",
      "Crawling: https://openai.com/careers/account-engineer\n",
      "Crawling: https://openai.com/careers/account-engineer#content\n",
      "Crawling: https://openai.com/careers/indirect-tax-lead\n",
      "Crawling: https://openai.com/blog/codex-apps\n",
      "Crawling: https://openai.com/blog/codex-apps#content\n",
      "Crawling: https://openai.com/blog?topics=product\n",
      "Crawling: https://openai.com/blog/codex-apps#OpenAI\n",
      "Crawling: https://openai.com/blog/openai-codex\n",
      "Crawling: https://openai.com/blog?authors=wojciech-zaremba\n",
      "Crawling: https://openai.com/blog/openai-codex#GregBrockman\n",
      "Crawling: https://openai.com/blog/openai-codex#content\n",
      "Crawling: https://openai.com/blog/openai-codex#OpenAI\n",
      "Crawling: https://openai.com/blog/openai-codex#WojciechZaremba\n",
      "Crawling: https://openai.com/blog?authors=greg-brockman\n",
      "Crawling: https://openai.com/careers/indirect-tax-lead#content\n",
      "Crawling: https://openai.com/blog/api-no-waitlist\n",
      "Crawling: https://openai.com/blog/api-no-waitlist#content\n",
      "Crawling: https://openai.com/blog/api-no-waitlist#OpenAI\n",
      "Crawling: https://openai.com/careers/software-engineer-front-endux\n",
      "Crawling: https://openai.com/careers/software-engineer-front-endux#content\n",
      "Crawling: https://openai.com/careers/software-engineer-model-inference\n",
      "Crawling: https://openai.com/careers/software-engineer-model-inference#content\n",
      "Crawling: https://openai.com/careers/software-engineer-safety\n",
      "Crawling: https://openai.com/careers/software-engineer-safety#content\n",
      "Crawling: https://openai.com/careers/software-engineer-full-stack-ai-scientist-team\n",
      "Crawling: https://openai.com/careers/software-engineer-full-stack-ai-scientist-team#content\n",
      "Crawling: https://openai.com/careers/research-scientist\n",
      "Crawling: https://openai.com/blog/jukebox\n",
      "Crawling: https://openai.com/research?models=jukebox\n",
      "Crawling: https://openai.com/research?authors=alec-radford\n",
      "Crawling: https://openai.com/research?topics=audio-generation\n",
      "Crawling: https://openai.com/blog/musenet\n",
      "Crawling: https://openai.com/research?models=musenet\n",
      "Crawling: https://openai.com/blog/better-language-models\n",
      "Crawling: https://openai.com/research?authors=david-luan\n",
      "Crawling: https://openai.com/research?authors=daniella-amodei\n",
      "Crawling: https://openai.com/research?authors=dario-amodei\n",
      "Crawling: https://openai.com/research/preparing-for-malicious-uses-of-ai\n",
      "Crawling: https://openai.com/research/preparing-for-malicious-uses-of-ai#content\n",
      "Crawling: https://openai.com/research/concrete-ai-safety-problems\n",
      "Crawling: https://openai.com/research/concrete-ai-safety-problems#content\n",
      "Crawling: https://openai.com/research?authors=greg-brockman\n",
      "Crawling: https://openai.com/research?topics=robustness\n",
      "Crawling: https://openai.com/research?authors=paul-christiano\n",
      "Crawling: https://openai.com/research?authors=michael-page\n",
      "Crawling: https://openai.com/research?authors=david-lansky\n",
      "Crawling: https://openai.com/research?authors=danny-hernandez\n",
      "Crawling: https://openai.com/research/language-unsupervised\n",
      "Crawling: https://openai.com/research?models=gpt\n",
      "Crawling: https://openai.com/research/unsupervised-sentiment-neuron\n",
      "Crawling: https://openai.com/research/unsupervised-sentiment-neuron#content\n",
      "Crawling: https://openai.com/research?authors=rafal-jozefowicz\n",
      "Crawling: https://openai.com/blog/unsupervised-sentiment-neuron/#methodology\n",
      "Crawling: https://openai.com/blog/unsupervised-sentiment-neuron/#sentimentneuron\n",
      "Crawling: https://openai.com/research/language-unsupervised#content\n",
      "Crawling: https://openai.com/research/better-language-models#content\n",
      "Crawling: https://openai.com/research?topics=unsupervised-learning\n",
      "Crawling: https://openai.com/research?models=gpt-2\n",
      "Crawling: https://openai.com/research/musenet#content\n",
      "Crawling: https://openai.com/blog/sparse-transformer\n",
      "Crawling: https://openai.com/research?authors=rewon-child\n",
      "Crawling: https://openai.com/research?topics=sparsity\n",
      "Crawling: https://openai.com/research?authors=scott-gray\n",
      "Crawling: https://openai.com/research/sparse-transformer#content\n",
      "Crawling: https://openai.com/blog/block-sparse-gpu-kernels\n",
      "Crawling: https://openai.com/research?authors=durk-kingma\n",
      "Crawling: https://openai.com/research/block-sparse-gpu-kernels#content\n",
      "Crawling: https://openai.com/research/block-sparse-gpu-kernels#small-world-lstms\n",
      "Crawling: https://openai.com/research/block-sparse-gpu-kernels#small-world\n",
      "Crawling: https://openai.com/blog/jukebox/#limitations\n",
      "Crawling: https://openai.com/research?authors=prafulla-dhariwal\n",
      "Crawling: https://openai.com/research?authors=christine-mcleavey-payne\n",
      "Crawling: https://openai.com/blog/jukebox/#rf33\n",
      "Crawling: https://openai.com/research?contentTypes=release\n",
      "Crawling: https://openai.com/five\n",
      "Crawling: https://openai.com/research/openai-five-defeats-dota-2-world-champions#content\n",
      "Crawling: https://openai.com/research/openai-five#rapid\n",
      "Crawling: https://openai.com/research/openai-five#restricted\n",
      "Crawling: https://openai.com/research?authors=jonas-schneider\n",
      "Crawling: https://openai.com/research/dota-2\n",
      "Crawling: https://openai.com/research/dota-2#content\n",
      "Crawling: https://openai.com/the-international\n",
      "HTTP Error: 404 for url: https://openai.com/the-international\n",
      "Request error for url: https://openai.com/the-international. Error details: 404 Client Error: Not Found for url: https://openai.com/the-international\n",
      "Crawling: https://openai.com/research/competitive-self-play\n",
      "Crawling: https://openai.com/research?authors=trapit-bansal\n",
      "Crawling: https://openai.com/research/competitive-self-play#content\n",
      "Crawling: https://openai.com/research?authors=igor-mordatch\n",
      "Crawling: https://openai.com/research/more-on-dota-2\n",
      "Crawling: https://openai.com/research/more-on-dota-2#content\n",
      "Crawling: https://openai.com/research?topics=environments\n",
      "Crawling: https://openai.com/research?topics=transfer-learning\n",
      "Crawling: https://openai.com/research?authors=larissa-schiavo\n",
      "Crawling: https://openai.com/research/generalizing-from-simulation\n",
      "Crawling: https://openai.com/research/generalizing-from-simulation#content\n",
      "Crawling: https://openai.com/blog/generalizing-from-simulation/#pusher_fail\n",
      "Crawling: https://openai.com/research?authors=josh-tobin\n",
      "Crawling: https://openai.com/research?authors=lerrel-pinto\n",
      "Crawling: https://openai.com/research?authors=marcin-andrychowicz\n",
      "Crawling: https://openai.com/research?authors=alex-ray\n",
      "Crawling: https://openai.com/research?topics=sim-to-real\n",
      "Crawling: https://openai.com/research?authors=wojciech-zaremba\n",
      "Crawling: https://openai.com/research?authors=peter-welinder\n",
      "Crawling: https://openai.com/research/learning-from-human-preferences\n",
      "Crawling: https://openai.com/research/learning-from-human-preferences#content\n",
      "Crawling: https://openai.com/blog/deep-reinforcement-learning-from-human-preferences/#bflip\n",
      "Crawling: https://openai.com/research?authors=pieter-abbeel\n",
      "Crawling: https://openai.com/research?topics=domain-randomization\n",
      "Crawling: https://openai.com/research?topics=robotics\n",
      "Crawling: https://openai.com/research?authors=bob-mcgrew\n",
      "Crawling: https://openai.com/research?authors=xue-bin-peng\n",
      "Crawling: https://openai.com/research?authors=brooke-chan\n",
      "Crawling: https://openai.com/research/learning-a-hierarchy\n",
      "Crawling: https://openai.com/research/learning-a-hierarchy#content\n",
      "Crawling: https://openai.com/research?authors=jonathan-ho\n",
      "Crawling: https://openai.com/research?authors=kevin-frans\n",
      "Crawling: https://openai.com/research?topics=meta-learning\n",
      "Crawling: https://openai.com/research?authors=peter-chen\n",
      "Crawling: https://openai.com/research?authors=jakub-pachocki\n",
      "Crawling: https://openai.com/research?authors=filip-wolski\n",
      "Crawling: https://openai.com/research/openai-five#observations\n",
      "Crawling: https://openai.com/research?authors=quirin-fischer\n",
      "Crawling: https://openai.com/research?authors=shariq-hashme\n",
      "Crawling: https://openai.com/research?authors=christopher-berner\n",
      "Crawling: https://openai.com/research?authors=jonathan-raiman\n",
      "Crawling: https://openai.com/research/spam-detection-in-the-physical-world\n",
      "Crawling: https://openai.com/research/spam-detection-in-the-physical-world#content\n",
      "Crawling: https://openai.com/research?authors=rachel-fong\n",
      "Crawling: https://openai.com/research/attacking-machine-learning-with-adversarial-examples\n",
      "Crawling: https://openai.com/research?authors=ian-goodfellow\n",
      "Crawling: https://openai.com/blog/openai-technical-goals\n",
      "Crawling: https://openai.com/blog/openai-technical-goals#content\n",
      "Crawling: https://openai.com/blog/openai-technical-goals#GregBrockman\n",
      "Crawling: https://openai.com/blog?authors=ilya-sutskever\n",
      "Crawling: https://openai.com/blog/generative-models\n",
      "Crawling: https://openai.com/research?authors=tim-salimans\n",
      "Crawling: https://openai.com/research?authors=rein-houthooft\n",
      "Crawling: https://openai.com/research?authors=andrej-karpathy\n",
      "Crawling: https://openai.com/blog/openai-gym-beta\n",
      "Crawling: https://openai.com/blog/team-plus-plus\n",
      "Crawling: https://openai.com/blog/team-plus-plus#content\n",
      "Crawling: https://openai.com/blog/team-plus-plus#GregBrockman\n",
      "Crawling: https://openai.com/research/openai-gym-beta#content\n",
      "Crawling: https://openai.com/blog/welcome-pieter-and-shivon\n",
      "Crawling: https://openai.com/blog/welcome-pieter-and-shivon#IlyaSutskever\n",
      "Crawling: https://openai.com/blog/welcome-pieter-and-shivon#content\n",
      "Crawling: https://openai.com/research/generative-models#content\n",
      "Crawling: https://openai.com/blog/generative-models/#going-forward\n",
      "Crawling: https://openai.com/research?authors=vicki-cheung\n",
      "Crawling: https://openai.com/blog?authors=sam-altman\n",
      "Crawling: https://openai.com/blog/openai-technical-goals#IlyaSutskever\n",
      "Crawling: https://openai.com/blog?topics=research\n",
      "Crawling: https://openai.com/blog/openai-technical-goals#SamAltman\n",
      "Crawling: https://openai.com/blog?authors=elon-musk\n",
      "Crawling: https://openai.com/blog/openai-technical-goals#ElonMusk\n",
      "Crawling: https://openai.com/research?authors=sandy-huang\n",
      "Crawling: https://openai.com/research/attacking-machine-learning-with-adversarial-examples#content\n",
      "Crawling: https://openai.com/research?topics=adversarial-examples\n",
      "Crawling: https://openai.com/research?authors=nicolas-papernot\n",
      "Crawling: https://openai.com/research?authors=yan-duan\n",
      "Crawling: https://openai.com/research?authors=christy-dennison\n",
      "Crawling: https://openai.com/research?authors=jie-tang\n",
      "Crawling: https://openai.com/research?authors=eric-sigler\n",
      "Crawling: https://openai.com/research?authors=diane-yoon\n",
      "Crawling: https://openai.com/research/openai-five#exploration\n",
      "Crawling: https://openai.com/research?authors=szymon-sidor\n",
      "Crawling: https://openai.com/research/more-on-dota-2#infrastructure\n",
      "Crawling: https://openai.com/research/openai-five#the-problem\n",
      "Crawling: https://openai.com/research?authors=christopher-hesse\n",
      "Crawling: https://openai.com/research?authors=susan-zhang\n",
      "Crawling: https://openai.com/research/openai-five#thegames\n",
      "Crawling: https://openai.com/research?authors=david-farhi\n",
      "Crawling: https://openai.com/research/more-on-dota-2#the-task\n",
      "Crawling: https://openai.com/research/openai-five#content\n",
      "Crawling: https://openai.com/research?authors=henrique-ponde\n",
      "Crawling: https://openai.com/research?authors=michael-petrov\n",
      "Crawling: https://openai.com/research?authors=przemyslaw-debiak\n",
      "Crawling: https://openai.com/blog/openai-five-benchmark\n",
      "Crawling: https://openai.com/blog/openai-five-benchmark#OpenAI\n",
      "Crawling: https://openai.com/blog/openai-five-benchmark#restrictions\n",
      "Crawling: https://openai.com/blog?topics=events\n",
      "Crawling: https://openai.com/blog/openai-five-benchmark/#restrictions\n",
      "Crawling: https://openai.com/blog/openai-five-benchmark#content\n",
      "Crawling: https://openai.com/blog/openai-five-benchmark-results\n",
      "Crawling: https://openai.com/research/openai-five-benchmark-results#content\n",
      "Crawling: https://openai.com/research/ai-and-compute\n",
      "Crawling: https://openai.com/research/ai-and-compute#appendixrecentnovelresultsthatusedmodestamountsofcompute\n",
      "Crawling: https://openai.com/blog/ai-and-compute/#modern\n",
      "Crawling: https://openai.com/research/ai-and-compute#content\n",
      "Crawling: https://openai.com/blog/ai-and-compute/#lookingforward\n",
      "Crawling: https://openai.com/research?authors=girish-sastry\n",
      "Crawling: https://openai.com/research?topics=self-play\n",
      "Crawling: https://openai.com/research/openai-five#our-approach\n",
      "Crawling: https://openai.com/research/openai-baselines-ppo\n",
      "Crawling: https://openai.com/research/roboschool\n",
      "Crawling: https://openai.com/research/roboschool#content\n",
      "Crawling: https://openai.com/research/openai-baselines-ppo#content\n",
      "Crawling: https://openai.com/research?topics=policy-optimization\n",
      "Crawling: https://openai.com/research?authors=oleg-klimov\n",
      "Crawling: https://openai.com/research?topics=dota-2\n",
      "Crawling: https://openai.com/blog/openai-five-finals\n",
      "Crawling: https://openai.com/five/#overview\n",
      "Crawling: https://openai.com/blog/openai-five-finals#OpenAI\n",
      "Crawling: https://openai.com/blog/the-international-2018-results\n",
      "Crawling: https://openai.com/research/the-international-2018-results#rules-change\n",
      "Crawling: https://openai.com/research/the-international-2018-results#content\n",
      "Crawling: https://openai.com/blog/openai-five-finals#content\n",
      "Crawling: https://openai.com/research/learning-dexterity\n",
      "Crawling: https://openai.com/research?models=dactyl\n",
      "Crawling: https://openai.com/research/ingredients-for-robotics-research\n",
      "Crawling: https://openai.com/research?authors=vikash-kumar\n",
      "Crawling: https://openai.com/research/openai-baselines-dqn\n",
      "Crawling: https://openai.com/blog/openai-baselines-dqn/#dqn\n",
      "Crawling: https://openai.com/research/openai-baselines-dqn#content\n",
      "Crawling: https://openai.com/research/requests-for-research-2\n",
      "Crawling: https://openai.com/research/requests-for-research-2#content\n",
      "Crawling: https://openai.com/research/ingredients-for-robotics-research#content\n",
      "Crawling: https://openai.com/research/learning-dexterity#content\n",
      "Crawling: https://openai.com/research?authors=matthias-plappert\n"
     ]
    }
   ],
   "source": [
    "#| eval : false\n",
    "crawl(\"https://openai.com/\",\"/home/hd/GptQA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
